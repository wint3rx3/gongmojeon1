{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6763771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íƒìƒ‰ëœ íŒŒì¼: ['data\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\\\\~$ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™© 2023ë…„ 1ë¶„ê¸°.csv', 'data\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\\\\~$ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™© 2023ë…„ 2ë¶„ê¸°.csv', 'data\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™© 2023ë…„ 1ë¶„ê¸°.csv', 'data\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™© 2023ë…„ 2ë¶„ê¸°.csv', 'data\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™© 2023ë…„ 3ë¶„ê¸°.csv', 'data\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™© 2023ë…„ 4ë¶„ê¸°.csv', 'data\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™© 2024ë…„ 1ë¶„ê¸°.csv', 'data\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\\\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™© 2024ë…„ 2ë¶„ê¸°.csv']\n",
      "0\n",
      "0\n",
      "440619\n",
      "791415\n",
      "629805\n",
      "591288\n",
      "398766\n",
      "830920\n",
      "ì´ 3682813í–‰ ë³‘í•© ì™„ë£Œ\n",
      "     H         ìˆœë²ˆ         ìì „ê±°ê³ ìœ ë²ˆí˜¸    ì‹œì‘ ëŒ€ì—¬ì†Œ                 ëŒ€ì—¬ì‹œê°„    ë°˜ë‚© ëŒ€ì—¬ì†Œ  \\\n",
      "0  NaN  5792004.0  001_0110_02091  SJ_00273  2023-01-01 00:07:55  SJ_00369   \n",
      "1  NaN  5792005.0  001_0110_01628  SJ_00244  2023-01-01 00:08:00  SJ_00400   \n",
      "2  NaN  5792006.0  001_0110_02899  SJ_00146  2023-01-01 00:08:07  SJ_00048   \n",
      "3  NaN  5792007.0  001_0110_02625  SJ_00580  2023-01-01 00:09:42  SJ_00580   \n",
      "4  NaN  5792008.0  001_0110_01914  SJ_00371  2023-01-01 00:10:30  SJ_00166   \n",
      "\n",
      "                  ë°˜ë‚©ì‹œê°„    ì£¼í–‰ê±°ë¦¬  ì£¼í–‰ì‹œê°„ í™˜ìŠ¹ ìœ ë¬´  \n",
      "0  2023-01-01 00:15:21   791.0   7.0     N  \n",
      "1  2023-01-01 00:17:18  1069.0   9.0     N  \n",
      "2  2023-01-01 00:37:15  3186.0  29.0     N  \n",
      "3  2023-01-01 00:10:40     0.0   1.0     N  \n",
      "4  2023-01-01 00:21:11    69.0  10.0     N  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "folder_path = \"data\\ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ì–´ìš¸ë§_ì´ìš©í˜„í™©\"\n",
    "file_list = glob.glob(os.path.join(folder_path, \"*.csv*\"))  # .xlsx ë˜ëŠ” .xls ëª¨ë‘ í¬í•¨\n",
    "print(\"íƒìƒ‰ëœ íŒŒì¼:\", file_list)\n",
    "\n",
    "# 2. ë³‘í•©\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, encoding='cp949')\n",
    "    print(len(df))\n",
    "    dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 3. ê²°ê³¼ í™•ì¸\n",
    "print(f\"ì´ {len(merged_df)}í–‰ ë³‘í•© ì™„ë£Œ\")\n",
    "print(merged_df.head())\n",
    "\n",
    "merged_df.to_csv(\"data/ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™©.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f203e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pulp import LpProblem, LpMaximize, LpVariable, lpSum\n",
    "from glob import glob\n",
    "\n",
    "# [1] ëŒ€ì—¬ì†Œ ìœ„ì¹˜ ë° kde ë°ì´í„° ë¡œë“œ\n",
    "station_df = pd.read_csv(\"result/ì–´ìš¸ë§_ëŒ€ì—¬ì†Œ_with_kde.csv\", encoding='utf-8-sig')\n",
    "station_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'] = station_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].astype(str).str.replace('SJ_', 'SJ-', regex=False)\n",
    "location_df = station_df[['ëŒ€ì—¬ì†Œ ì•„ì´ë””', 'ìœ„ë„', 'ê²½ë„', 'kde_density_norm']].dropna()\n",
    "\n",
    "# [2] ì´ìš©í˜„í™© íŒŒì¼ ë³‘í•©\n",
    "usage_file_list = glob(\"data/ì„¸ì¢…ë„ì‹œêµí†µê³µì‚¬_ê³µê³µìì „ê±°(ì–´ìš¸ë§) ì´ìš© í˜„í™©.csv\")\n",
    "usage_dfs = []\n",
    "\n",
    "for file in usage_file_list:\n",
    "    df = pd.read_csv(file, encoding='utf-8')\n",
    "    df['ì‹œì‘ ëŒ€ì—¬ì†Œ'] = df['ì‹œì‘ ëŒ€ì—¬ì†Œ'].astype(str).str.replace('SJ_', 'SJ-', regex=False)\n",
    "    df = df.rename(columns={'ì‹œì‘ ëŒ€ì—¬ì†Œ': 'ëŒ€ì—¬ì†Œ ì•„ì´ë””'})\n",
    "    usage_dfs.append(df[['ëŒ€ì—¬ì†Œ ì•„ì´ë””']])\n",
    "\n",
    "usage_df = pd.concat(usage_dfs, ignore_index=True)\n",
    "\n",
    "# [3] ìˆ˜ìš” ì§‘ê³„\n",
    "demand_df = usage_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].value_counts().reset_index()\n",
    "demand_df.columns = ['ëŒ€ì—¬ì†Œ ì•„ì´ë””', 'ìˆ˜ìš”']\n",
    "\n",
    "# [4] ìˆ˜ìš” + kde + ìœ„ì¹˜ ê²°í•©\n",
    "merged_df = pd.merge(demand_df, location_df, on='ëŒ€ì—¬ì†Œ ì•„ì´ë””')\n",
    "demand_ids = merged_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].tolist()\n",
    "candidate_ids = location_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].tolist()\n",
    "\n",
    "merged_df['ìˆ˜ìš”_norm'] = (merged_df['ìˆ˜ìš”'] - merged_df['ìˆ˜ìš”'].min()) / (merged_df['ìˆ˜ìš”'].max() - merged_df['ìˆ˜ìš”'].min())\n",
    "merged_df['ì¤‘ìš”ë„'] = 0.5 * merged_df['ìˆ˜ìš”_norm'] + 0.5 * merged_df['kde_density_norm']\n",
    "importance_dict = merged_df.set_index('ëŒ€ì—¬ì†Œ ì•„ì´ë””')['ì¤‘ìš”ë„'].to_dict()\n",
    "\n",
    "# [5] ë²¡í„°í™”ëœ ì»¤ë²„ë¦¬ì§€ í–‰ë ¬ ê³„ì‚° (Haversine)\n",
    "coverage_radius_km = 0.5\n",
    "demand_coords = location_df[location_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].isin(demand_ids)].copy()\n",
    "candidate_coords = location_df[location_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].isin(candidate_ids)].copy()\n",
    "\n",
    "d_lat = np.radians(demand_coords['ìœ„ë„'].values.reshape(-1, 1))\n",
    "d_lon = np.radians(demand_coords['ê²½ë„'].values.reshape(-1, 1))\n",
    "c_lat = np.radians(candidate_coords['ìœ„ë„'].values.reshape(1, -1))\n",
    "c_lon = np.radians(candidate_coords['ê²½ë„'].values.reshape(1, -1))\n",
    "\n",
    "R = 6371.0\n",
    "dlat = c_lat - d_lat\n",
    "dlon = c_lon - d_lon\n",
    "a = np.sin(dlat / 2)**2 + np.cos(d_lat) * np.cos(c_lat) * np.sin(dlon / 2)**2\n",
    "c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "dist_matrix = R * c\n",
    "coverage_bool = dist_matrix <= coverage_radius_km\n",
    "\n",
    "coverage_matrix = {\n",
    "    (demand_id, candidate_id): bool(coverage_bool[i, j])\n",
    "    for i, demand_id in enumerate(demand_coords['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].values)\n",
    "    for j, candidate_id in enumerate(candidate_coords['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].values)\n",
    "}\n",
    "\n",
    "# [6] ìë™ íƒìƒ‰ MCLP: ëª©í‘œ ì»¤ë²„ìœ¨ ë§Œì¡±í•˜ëŠ” ìµœì†Œ p íƒìƒ‰\n",
    "target_coverage_ratio = 0.95\n",
    "total_importance = sum(importance_dict[i] for i in demand_ids)\n",
    "best_p = None\n",
    "best_selected_sites = None\n",
    "\n",
    "for p in range(1, 31):\n",
    "    model = LpProblem(\"MCLP\", LpMaximize)\n",
    "    x = LpVariable.dicts(\"Candidate\", candidate_ids, cat='Binary')\n",
    "    y = LpVariable.dicts(\"Demand\", demand_ids, cat='Binary')\n",
    "\n",
    "    model += lpSum(y[i] * importance_dict[i] for i in demand_ids)\n",
    "\n",
    "    for i in demand_ids:\n",
    "        model += y[i] <= lpSum(x[j] for j in candidate_ids if coverage_matrix.get((i, j), False))\n",
    "    model += lpSum(x[j] for j in candidate_ids) <= p\n",
    "\n",
    "    model.solve()\n",
    "\n",
    "    covered_importance = sum(importance_dict[i] for i in demand_ids if y[i].varValue == 1)\n",
    "    coverage_ratio = covered_importance / total_importance\n",
    "    print(f\"p = {p}, ì»¤ë²„ëœ ì¤‘ìš”ë„ = {covered_importance:.4f} ({coverage_ratio:.2%})\")\n",
    "\n",
    "    if coverage_ratio >= target_coverage_ratio:\n",
    "        best_p = p\n",
    "        best_selected_sites = [j for j in candidate_ids if x[j].varValue == 1]\n",
    "        break\n",
    "\n",
    "# [7] ê²°ê³¼ ì €ì¥\n",
    "if best_p is not None:\n",
    "    print(f\"\\nâœ… ìµœì ì˜ p = {best_p} (ì»¤ë²„ìœ¨ â‰¥ {target_coverage_ratio:.0%})\")\n",
    "    print(\"\\nğŸ“ ìµœì¢… ì„ ì •ëœ ëŒ€ì—¬ì†Œ í›„ë³´ì§€ ID ëª©ë¡:\")\n",
    "    for i, site in enumerate(best_selected_sites, 1):\n",
    "        print(f\"{i:2d}. {site}\")\n",
    "\n",
    "    # ì €ì¥\n",
    "    selected_df = location_df[location_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].isin(best_selected_sites)].copy()\n",
    "    selected_df['ì„ ì •ì—¬ë¶€'] = 'ì„ ì •ë¨'\n",
    "    selected_df.to_csv(f\"result/MCLP_ì„ ì •_ëŒ€ì—¬ì†Œ_p{best_p}.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "    merged_df['ì»¤ë²„ì—¬ë¶€'] = merged_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].apply(\n",
    "        lambda i: int(y[i].varValue) if i in y else 0\n",
    "    )\n",
    "    merged_df.to_csv(f\"result/MCLP_ìˆ˜ìš”ì§€_ì»¤ë²„ì—¬ë¶€_p{best_p}.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: result/MCLP_ì„ ì •_ëŒ€ì—¬ì†Œ_p{best_p}.csv\")\n",
    "    print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: result/MCLP_ìˆ˜ìš”ì§€_ì»¤ë²„ì—¬ë¶€_p{best_p}.csv\")\n",
    "else:\n",
    "    print(\"âŒ ëª©í‘œ ì»¤ë²„ìœ¨ì„ ë§Œì¡±í•˜ëŠ” pë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed333208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ í›„ë³´ì§€ì— ëŒ€í•´ ì„ ì •ì—¬ë¶€ í‘œì‹œ (ì„ ì •: 'ì„ ì •ë¨', ë¯¸ì„ ì •: 'ë¯¸ì„ ì •')\n",
    "full_station_df = location_df.copy()\n",
    "full_station_df['ì„ ì •ì—¬ë¶€'] = full_station_df['ëŒ€ì—¬ì†Œ ì•„ì´ë””'].apply(\n",
    "    lambda x: 'ì„ ì •ë¨' if x in best_selected_sites else 'ë¯¸ì„ ì •'\n",
    ")\n",
    "\n",
    "# ì €ì¥\n",
    "full_station_df.to_csv(f\"result/MCLP_ì „ì²´_ëŒ€ì—¬ì†Œ_ì„ ì •ì—¬ë¶€í¬í•¨_p{best_p}.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
